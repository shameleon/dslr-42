{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainset data prior analysis\n",
    "- down to to 10 meaningful features\n",
    "- standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'../datasets/dataset_train.csv')\n",
    "df_class = df['Hogwarts House']\n",
    "df_class.head()\n",
    "\n",
    "# df['Hogwarts House'] works for only 1 col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df[df.columns[6:]]\n",
    "df_features.head()\n",
    "# removed non_num = ['Index', 'First Name', 'Last Name', 'Birthday', 'Best Hand',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(\n",
    " data=df, \n",
    " x=\"Astronomy\",\n",
    " y=\"Defense Against the Dark Arts\",\n",
    " hue=\"Hogwarts House\",\n",
    " legend='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Only the meaningful variables should be included.\n",
    "    The independent variables should be independent of each other. That is, the model should have little or no multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(\n",
    " data=df, \n",
    " x=\"Astronomy\",\n",
    " y=\"Defense Against the Dark Arts\",\n",
    " hue=\"Hogwarts House\",\n",
    " legend='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"Hogwarts House\", y=\"Arithmancy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"Hogwarts House\", y=\"Care of Magical Creatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Only the meaningful variables should be included.\n",
    "    The independent variables should be independent of each other. \n",
    "    That is, the model should have little or no multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features = [\"Arithmancy\", \"Defense Against the Dark Arts\", \"Care of Magical Creatures\"]\n",
    "df_features = df_features.drop(excluded_features, axis=1)\n",
    "df_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_features.columns.to_list()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization\n",
    "```df_features```\n",
    "apply along axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.apply(np.mean) #axis=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(arr:np.ndarray):\n",
    "    mean = np.mean(arr)\n",
    "    std = np.std(arr)\n",
    "    return (arr - mean) / std\n",
    "\n",
    "df_std_features = df_features.agg(lambda course:standardize(course))\n",
    "df_std_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_std_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates if any\n",
    "remove full na row if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the 4 classes in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hogwarts House'].unique()\n",
    "# houses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-vs-all :\n",
    "actual class y set to 1 or 0\n",
    "1= is in house, 0= is in another house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = df['Hogwarts House'].unique()\n",
    "houses[0]\n",
    "# gives bool : df['Hogwarts House'] == houses[0]\n",
    "y_actual = np.where(df['Hogwarts House'] == houses[0], 1, 0)\n",
    "y_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dot product :\n",
    "X.weights = output\n",
    "\n",
    "tranpose weights : weights is a vertical array. 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transposed\n",
    "```weights = np.ones(1 + len(features)).T```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.array(df_std_features)\n",
    "x_train = np.array(df_std_features.fillna(0))\n",
    "weights = np.ones(len(features)).T\n",
    "z_output = np.dot(x_train, weights)\n",
    "z_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function (or logistic function) to map input values from a wide range into a limited interval. \n",
    "$sigmoid function$\n",
    "$$\n",
    "y = g(z) = \\frac{1}{1 + e^{-z}} = \\frac{e^z}{1 + e^z}\n",
    "$$\n",
    "This formula represents the probability of observing the output y = 1 of a Bernoulli random variable. This variable is either 1 or 0 (y \\in {0,1})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(arr:np.ndarray):\n",
    "    return 1 / (1 + np.exp(-arr))\n",
    "\n",
    "h_pred = sigmoid(z_output)\n",
    "print(h_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z_output), len(h_pred), len(y_actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latex examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align} \\mathbf{a} \\cdot \\mathbf{b} &= \\sum_{i=1}^n a_i b_i \\\\ &= a_x b_x + a_y b_y + a_z b_z. \\end{align}\n",
    "\n",
    "\\begin{align} \\sigma^2 = \\begin{pmatrix} \\sigma_1^2 & \\sigma_{12}^2 \\\\ \\sigma_{12}^2 & \\sigma_2^2 \\end{pmatrix}. \\end{align}\n",
    "\n",
    "\\begin{align} P(\\sigma) = \\left\\{ \\begin{array}{cl} \\sigma^{-1} & \\sigma > 0 \\\\ 0 & \\sigma \\le 0. \\end{array} \\right. \\end{align}\n",
    "\n",
    " \\begin{pmatrix} \\sigma_1^2 & \\sigma_{12}^2 \\\\ \\sigma_{12}^2 & \\sigma_2^2 \\end{pmatrix}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,0.5 ],[2,0,1],[0,np.nan,0.8,],[2.5,1.2,0.4]]) \n",
    "b = np.array([[2,3,4]]) \n",
    "print(np.dot(a, b.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask array to avoi NaN\n",
    "v1_m = np.ma.array(a, mask=np.isnan(a))\n",
    "v2_m = np.ma.array(b, mask=np.isnan(b))\n",
    "print(np.ma.dot(v1_m, v2_m.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_actual, h_pred):\n",
    "    \"\"\" y_actual : target class. 1 in class, 0 not in class\n",
    "    h_pred = signoid(x.weights)\n",
    "    loss = (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \"\"\"\n",
    "    m = len(h_pred)\n",
    "    a = -y_actual * np.log(h_pred)\n",
    "    b = (1 - y_actual) * np.log(1 - h_pred)\n",
    "    return (a - b) / m\n",
    "\n",
    "loss(y_actual, h_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The weights are updated by substracting the derivative (gradient descent) times the learning rate,\n",
    "loss'(theta) = \n",
    "def gradient_descent(X, h, y):\n",
    "    return np.dot(X.T, (h - y)) / y.shape[0]\n",
    "def update_weight_loss(weight, learning_rate, gradient):\n",
    "    return weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_m = np.ma.array(x_train, mask=np.isnan(x_train))\n",
    "res = (h_pred - y_actual)\n",
    "v2_m = np.ma.array(res, mask=np.isnan(res))\n",
    "#dot = np.ma.dot(x_train, v2_m.T)\n",
    "dot = np.ma.dot(v1_m.T, v2_m)\n",
    "gradient1 = dot / y_actual.shape[0]\n",
    "gradient1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace np.nan with zeros\n",
    "```x_train[np.isnan(x_train)] = 0 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot = np.dot(x_train.T, (h_pred - y_actual))\n",
    "gradient = dot / y_actual.shape[0]\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x_train, h_pred, y_actual):\n",
    "    return np.dot(x_train.T, (h_pred - y_actual)) / y_actual.shape[0]\n",
    "\n",
    "def update_weight_loss(weight, learning_rate, gradient):\n",
    "    return weight - learning_rate * gradient\n",
    "\n",
    "gd =gradient_descent(x_train, h_pred, gradient)\n",
    "print(\"gd = \", gd)\n",
    "weights = update_weight_loss(weights, 0.1, gradient_descent(x_train, h_pred, y_actual))\n",
    "print(\" w =\", weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The weights are updated by substracting the derivative (gradient descent) times the learning rate,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
